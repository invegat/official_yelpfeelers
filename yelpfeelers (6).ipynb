{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from pandas.io.json import json_normalize\n",
    "pd.set_option(\"display.max_columns\", 0)\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from sqlalchemy.dialects.postgresql import JSON\n",
    "from flask import Flask\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import numpy as np\n",
    "import json\n",
    "from psycopg2.extras import Json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "print(f'TensorFlow Version: {tf.__version__}')\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 24.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement not upgraded as not directly required: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "Requirement not upgraded as not directly required: singledispatch in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nltk) (3.4.0.3)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Found existing installation: nltk 3.3\n",
      "    Uninstalling nltk-3.3:\n",
      "      Successfully uninstalled nltk-3.3\n",
      "Successfully installed nltk-3.4\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 92.5MB 587kB/s eta 0:00:011    69% |██████████████████████▍         | 64.7MB 88.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/dc/5503d89e530988eb7a1aed337dcb456ef8150f7c06132233bd9e41ec0215/grpcio-1.19.0-cp36-cp36m-manylinux1_x86_64.whl (10.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.8MB 5.9MB/s  eta 0:00:01 8% |██▊                             | 901kB 91.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 1.1MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/60/ca38e967360212ddbb004141a70f5f6d47296e1fba37964d8ac6cb631921/protobuf-3.7.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 37.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 58.1MB/s a 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 42.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 50.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 44.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.14.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 53.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.1)\n",
      "Building wheels for collected packages: absl-py, termcolor, gast\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built absl-py termcolor gast\n",
      "Installing collected packages: grpcio, protobuf, markdown, absl-py, tensorboard, astor, termcolor, keras-preprocessing, gast, tensorflow-estimator, keras-applications, tensorflow\n",
      "  Found existing installation: protobuf 3.6.0\n",
      "    Uninstalling protobuf-3.6.0:\n",
      "      Successfully uninstalled protobuf-3.6.0\n",
      "Successfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 grpcio-1.19.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 protobuf-3.7.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "BUSINESS_DATABASE_URL = os.getenv(\"BUSINESS_DATABASE_URL\")\n",
    "BUSINESS_TEST = os.getenv(\"BUSINESS_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('postgres://kvpmewwuocndeu:290d7143d73ce041095858b8c8d22c2cfcc99cdca16dbc3ff2ab5f2d5df35108@ec2-75-101-133-29.compute-1.amazonaws.com:5432/d3ckh7s6ihh2al',\n",
       " 'postgres://juwwvohcorbolo:ce3d8c3e671044f8e15c880db71ce26146826e3f126da53a55788f7f0a7a54ae@ec2-23-23-173-30.compute-1.amazonaws.com:5432/d4l0sqaog7kpe0',\n",
       " 'postgres://jnxpcmkaaavqwv:bdd7c44b57e1ff20d16a85238b87cba387260d45054b969f68417bc8a8963508@ec2-50-17-227-28.compute-1.amazonaws.com:5432/d99mq010h4mk44')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUSINESS_DATABASE_URL, DATABASE_URL, BUSINESS_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True, join_at_end = False):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        # We are not using \"text.split()\" here\n",
    "        #since it is not fool proof, e.g. words followed by punctuations \"Are you kidding?I think you aren't.\"\n",
    "        text = re.findall(r\"[\\w']+\", text)\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)# remove links\n",
    "    text = re.sub(r'\\<a href', ' ', text)# remove html link tag\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        if join_at_end:\n",
    "            text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv_transformer = CountVectorizer(analyzer = clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv_transformer.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x,df.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(x[2:3])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pstar'] = nb.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ctext</th>\n",
       "      <th>pstar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>total bill horrible service 8gs crooks actuall...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>adore travis hard rock new kelly cardenas salo...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>say office really together organized friendly ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>went lunch steak sandwich delicious caesar sal...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>today second three sessions paid although firs...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  ...    pstar\n",
       "0  ujmEBvifdJM6h6RLv4wQIg  ...      1.0\n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ  ...      5.0\n",
       "2  WTqjgwHlXbSFevF32_DJVw  ...      5.0\n",
       "3  ikCg8xy5JIg_NGPx-MSIDA  ...      4.0\n",
       "4  b1b1eb3uo-w561D0ZfCEiQ  ...      1.0\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open('region_df_pstar_ptext.pql', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !chmod 600 /home/ec2-user/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d yelp-dataset/yelp-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip yelp-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('yelp_academic_dataset_user.json') as file:\n",
    "    for line in file:\n",
    "        j = json.loads(line)\n",
    "        data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637138, 22)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dfu.user_id.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2015,2016,2017</td>\n",
       "      <td>5</td>\n",
       "      <td>c78V-rj8NQcQjOI8KP3UEA, alRMgPcngYSCJ5naFRBz5g...</td>\n",
       "      <td>17</td>\n",
       "      <td>Rashmi</td>\n",
       "      <td>95</td>\n",
       "      <td>84</td>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>2013-10-08 23:11:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>kEBTgDvFX754S68FllfCaA, aB2DynOxNOJK9st2ZeGTPg...</td>\n",
       "      <td>22</td>\n",
       "      <td>Jenna</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>4XChL029mKr5hydo79Ljxg</td>\n",
       "      <td>2013-02-21 22:29:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4N-HU_T32hLENLntsNKNBg, pSY2vwWLgWfGVAAiKQzMng...</td>\n",
       "      <td>8</td>\n",
       "      <td>David</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>bc8C_eETBWL0olvFSJJd0w</td>\n",
       "      <td>2013-10-04 00:16:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>RZ6wS38wnlXyj-OOdTzBxA, l5jxZh1KsgI8rMunm-GN6A...</td>\n",
       "      <td>4</td>\n",
       "      <td>Angela</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>dD0gZpBctWGdWo9WlGuhlA</td>\n",
       "      <td>2014-05-22 15:57:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.08</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>665</td>\n",
       "      <td>2015,2016,2017,2018</td>\n",
       "      <td>39</td>\n",
       "      <td>mbwrZ-RS76V1HoJ0bF_Geg, g64lOV39xSLRZO0aQQ6DeQ...</td>\n",
       "      <td>279</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>361</td>\n",
       "      <td>1114</td>\n",
       "      <td>MM4RJAeH6yuaN8oZDSt0RA</td>\n",
       "      <td>2013-10-23 07:02:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars         ...                 yelping_since\n",
       "0           4.03         ...           2013-10-08 23:11:33\n",
       "1           3.63         ...           2013-02-21 22:29:06\n",
       "2           3.71         ...           2013-10-04 00:16:10\n",
       "3           4.85         ...           2014-05-22 15:57:30\n",
       "4           4.08         ...           2013-10-23 07:02:50\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dfu, open('dfu.pql', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('yelp_academic_dataset_review.json') as file:\n",
    "    for line in file:\n",
    "        j = json.loads(line)\n",
    "        data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685900"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open('data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[len(data) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df[['stars', 'pstar', 'business_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open('review_df.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftm = dft.groupby('business_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192606, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>pstar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--1UhMGODdWsrMastO9DZw</th>\n",
       "      <td>4.076923</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <td>3.173913</td>\n",
       "      <td>3.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--7zmmkVg-IMGaXbuVd0SQ</th>\n",
       "      <td>3.898305</td>\n",
       "      <td>4.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--8LPVSo5i0Oo61X01sV9A</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--9QQLMTbFzLJ_oT-ON3Xw</th>\n",
       "      <td>3.307692</td>\n",
       "      <td>4.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           stars     pstar\n",
       "business_id                               \n",
       "--1UhMGODdWsrMastO9DZw  4.076923  4.500000\n",
       "--6MefnULPED_I942VcFNA  3.173913  3.739130\n",
       "--7zmmkVg-IMGaXbuVd0SQ  3.898305  4.525424\n",
       "--8LPVSo5i0Oo61X01sV9A  3.500000  5.000000\n",
       "--9QQLMTbFzLJ_oT-ON3Xw  3.307692  4.307692"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbdfr = bdfr.join(dftm, on=\"business_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192609, 16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jbdfr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'business_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'business_id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-83b7f315a31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdftm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbdfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   5314\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5315\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 5316\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   5317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5318\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   5329\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   5330\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5331\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   5332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     55\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    563\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    564\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m                     \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'business_id'"
     ]
    }
   ],
   "source": [
    "dftm.join(bdfr.set_index('business_id'), on=\"business_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6685900, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id           ...                           user_id\n",
       "0  ujmEBvifdJM6h6RLv4wQIg           ...            hG7b0MtEbXx5QzbzE6C_VA\n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ           ...            yXQM5uF2jS6es16SJzNHfg\n",
       "2  WTqjgwHlXbSFevF32_DJVw           ...            n6-Gk65cPZL6Uz8qRm3NYw\n",
       "3  ikCg8xy5JIg_NGPx-MSIDA           ...            dacAIZ6fTM6mqwW5uxkskg\n",
       "4  b1b1eb3uo-w561D0ZfCEiQ           ...            ssoyf2_x0EQMed6fgHeMyQ\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "df['ctext'] = df.text.apply(lambda t: clean_text(t, join_at_end = True))\n",
    "# clean_texts = []\n",
    "# for text in df.review:\n",
    "#     clean_texts.append(clean_text(text))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df, open('review_df_ctext.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('yelp_academic_dataset_business.json') as file:\n",
    "    for line in file:\n",
    "        j = json.loads(line)\n",
    "        data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192609, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bdf[2:3].attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'attributes', 'business_id', 'categories', 'city', 'hours',\n",
       "       'is_open', 'latitude', 'longitude', 'name', 'postal_code',\n",
       "       'review_count', 'business_stars', 'state', 'stars', 'pstar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jbdfr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>state</th>\n",
       "      <th>stars</th>\n",
       "      <th>pstar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2818 E Camino Acequia Drive</td>\n",
       "      <td>{'GoodForKids': 'False'}</td>\n",
       "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
       "      <td>Golf, Active Life</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>Arizona Biltmore Golf Club</td>\n",
       "      <td>85016</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'GoodForMe...</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ON</td>\n",
       "      <td>2.738806</td>\n",
       "      <td>3.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10110 Johnston Rd, Ste 15</td>\n",
       "      <td>{'GoodForKids': 'True', 'NoiseLevel': 'u'avera...</td>\n",
       "      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.092564</td>\n",
       "      <td>-80.859132</td>\n",
       "      <td>Musashi Japanese Restaurant</td>\n",
       "      <td>28210</td>\n",
       "      <td>170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>4.073034</td>\n",
       "      <td>4.449438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15655 W Roosevelt St, Ste 237</td>\n",
       "      <td>None</td>\n",
       "      <td>xvX2CttrVhyG2z1dFg_0xw</td>\n",
       "      <td>Insurance, Financial Services</td>\n",
       "      <td>Goodyear</td>\n",
       "      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.455613</td>\n",
       "      <td>-112.395596</td>\n",
       "      <td>Farmers Insurance - Paul Lorenz</td>\n",
       "      <td>85338</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4209 Stuart Andrew Blvd, Ste F</td>\n",
       "      <td>{'BusinessAcceptsBitcoin': 'False', 'ByAppoint...</td>\n",
       "      <td>HhyxOkGAM07SRYtlQ4wMFQ</td>\n",
       "      <td>Plumbing, Shopping, Local Services, Home Servi...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.190012</td>\n",
       "      <td>-80.887223</td>\n",
       "      <td>Queen City Plumbing</td>\n",
       "      <td>28217</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address    ...        pstar\n",
       "0     2818 E Camino Acequia Drive    ...     4.000000\n",
       "1            30 Eglinton Avenue W    ...     3.731343\n",
       "2       10110 Johnston Rd, Ste 15    ...     4.449438\n",
       "3   15655 W Roosevelt St, Ste 237    ...     5.000000\n",
       "4  4209 Stuart Andrew Blvd, Ste F    ...     5.000000\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jbdfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfd_hours = bdf.hours.dropna()\n",
    "max(bdf.state.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdfr = bdf.rename(index=str, columns={\"stars\": \"business_stars\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP = Flask(__name__)\n",
    "APP.config['SQLALCHEMY_DATABASE_URI'] = BUSINESS_DATABASE_URL\n",
    "APP.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# APP.config['SQLALCHEMY_BINDS'] = {\n",
    "#     'reviewtwo': DATABASE_URL\n",
    "# }\n",
    "APP.config['extend_existing']=True\n",
    "DB = SQLAlchemy(APP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ebusiness(DB.Model):\n",
    "    id = DB.Column(DB.Integer, primary_key=True)\n",
    "    address = DB.Column(DB.String(128), nullable=False) \n",
    "    attributes = DB.Column(JSON)\n",
    "    business_id = DB.Column(DB.String(25), nullable=False)\n",
    "    categories = DB.Column(DB.String(1024), nullable=True)\n",
    "    city = DB.Column(DB.String(64), nullable=False)\n",
    "    hours = DB.Column(JSON, nullable=True)\n",
    "    is_open = DB.Column(DB.Integer, nullable=False)\n",
    "    latitude = DB.Column(DB.Float, nullable=False)\n",
    "    longitude = DB.Column(DB.Float, nullable=False)\n",
    "    name = DB.Column(DB.String(64), nullable=False)\n",
    "    postal_code = DB.Column(DB.String(8), nullable=False)\n",
    "    review_count = DB.Column(DB.BigInteger, nullable=False)\n",
    "    business_stars = DB.Column(DB.Float, nullable=False)\n",
    "    state = DB.Column(DB.String(3), nullable=False)\n",
    "    average_stars = DB.Column(DB.Float, nullable=False)\n",
    "    average_pstars = DB.Column(DB.Float, nullable=False)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Attributes {self.attributes} ---  Address {self.address} ---  Name {self.name} -- Stars {self.business_stars} -- Hours {self.hours}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.drop_all()\n",
    "DB.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "?json.dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 10000 done 20000 done 30000 done 40000 done 50000 done 60000 done 70000 done 80000 done 90000 done 100000 done 110000 done 120000 done 130000 done 140000 done 150000 done 160000 done 170000 done 180000 done 190000 done 192609 "
     ]
    }
   ],
   "source": [
    "\n",
    "target = jbdfr.shape[0]\n",
    "done = 0\n",
    "step = 10000\n",
    "while done < target:\n",
    "    todo = min(target - done, step)\n",
    "    for row in np.ascontiguousarray(jbdfr[done:done+todo].values):\n",
    "        #print(type(row[1]), row[1])\n",
    "#         json.dumps(row[1].__dict__)\n",
    "        dictionarya = json.dumps(row[1])\n",
    "        dictionaryh = json.dumps(row[5])\n",
    "#         print(dictionary)\n",
    "        dgo = ebusiness(address=row[0],attributes=dictionarya, business_id=row[2], categories=row[3],\n",
    "                     city=row[4], hours=dictionaryh, is_open=row[6], latitude=row[7], longitude=row[8], name=row[9], \n",
    "                      postal_code=row[10], review_count=row[11], business_stars = row[12], state=row[13],\n",
    "                       average_stars=row[14], average_pstars=row[15]\n",
    "                      )\n",
    "        DB.session.add(dgo)\n",
    "    DB.session.commit()\n",
    "    done += todo\n",
    "    print('done', done, end=\" \")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes {\"GoodForKids\": \"True\", \"NoiseLevel\": \"u'average'\", \"RestaurantsDelivery\": \"False\", \"GoodForMeal\": \"{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': True, 'brunch': False, 'breakfast': False}\", \"Alcohol\": \"u'beer_and_wine'\", \"Caters\": \"False\", \"WiFi\": \"u'no'\", \"RestaurantsTakeOut\": \"True\", \"BusinessAcceptsCreditCards\": \"True\", \"Ambience\": \"{'romantic': False, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': False, 'trendy': False, 'upscale': False, 'casual': True}\", \"BusinessParking\": \"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\", \"RestaurantsTableService\": \"True\", \"RestaurantsGoodForGroups\": \"True\", \"OutdoorSeating\": \"False\", \"HasTV\": \"True\", \"BikeParking\": \"True\", \"RestaurantsReservations\": \"True\", \"RestaurantsPriceRange2\": \"2\", \"RestaurantsAttire\": \"'casual'\"} ---  Address 10110 Johnston Rd, Ste 15 ---  Name Musashi Japanese Restaurant -- Stars 4.0 -- Hours {\"Monday\": \"17:30-21:30\", \"Wednesday\": \"17:30-21:30\", \"Thursday\": \"17:30-21:30\", \"Friday\": \"17:30-22:0\", \"Saturday\": \"17:30-22:0\", \"Sunday\": \"17:30-21:0\"}\n"
     ]
    }
   ],
   "source": [
    "for row in DB.session.query(business).filter(business.business_id =='gnKjwL_1w79qoiV3IC_xQQ'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf = df.join(bdfr.set_index('business_id'), on=\"business_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf[jdf.business_stars.notnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/14/501508b016e7b1ad0eb91bba581e66ad9bfc7c66fcacbb580eaf9bc38458/python_dotenv-0.10.1-py2.py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.10.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/85/97db05dd8f6adff57cd1cb8acceeffdaf4724efec18b9af23f3cd75ad089/psycopg2_binary-2.7.7-cp36-cp36m-manylinux1_x86_64.whl (2.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.7MB 17.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.7.7\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask_sqlalchemy\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/44/294fb7f6bf49cc7224417cd0637018db9fee0729b4fe166e43e2bbb1f1c8/Flask_SQLAlchemy-2.3.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Flask>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask_sqlalchemy) (1.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=0.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask_sqlalchemy) (1.2.11)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Flask>=0.10->flask_sqlalchemy) (0.14.1)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Flask>=0.10->flask_sqlalchemy) (2.10)\n",
      "Requirement already satisfied: click>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Flask>=0.10->flask_sqlalchemy) (6.7)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Flask>=0.10->flask_sqlalchemy) (0.24)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Jinja2>=2.10->Flask>=0.10->flask_sqlalchemy) (1.0)\n",
      "Installing collected packages: flask-sqlalchemy\n",
      "Successfully installed flask-sqlalchemy-2.3.2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flask_sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP.config['SQLALCHEMY_DATABASE_URI'] = DATABASE_URL\n",
    "APP.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# APP.config['SQLALCHEMY_BINDS'] = {\n",
    "#     'reviewtwo': DATABASE_URL\n",
    "# }\n",
    "APP.config['extend_existing']=True\n",
    "DB = SQLAlchemy(APP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
       "       'useful', 'user_id', 'ctext', 'pstar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4773"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df.ctext.apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id     object\n",
       "cool             int64\n",
       "date            object\n",
       "funny            int64\n",
       "review_id       object\n",
       "stars          float64\n",
       "text            object\n",
       "useful           int64\n",
       "user_id         object\n",
       "ctext           object\n",
       "pstar          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.5 :: Anaconda custom (64-bit)\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class review(DB.Model):\n",
    "    id = DB.Column(DB.Integer, primary_key=True)\n",
    "    business_id = DB.Column(DB.String(25), nullable=False)\n",
    "    date = DB.Column(DB.DateTime, nullable=False)\n",
    "    stars = DB.Column(DB.Integer, nullable=False)\n",
    "    pstars = DB.Column(DB.Integer, nullable=False)\n",
    "    text = DB.Column(DB.String(5000), nullable=False)\n",
    "    ctext = DB.Column(DB.String(5000), nullable=False)\n",
    "    user_id = DB.Column(DB.String(25), nullable=False)\n",
    "    review_id = DB.Column(DB.String(25), nullable=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Data {self.date} ---  Text {self.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in np.ascontiuousarray(X_train)df.iterrows():\n",
    "#         if (index > 1) and (index % 2 == 0):\n",
    "#             print(index)\n",
    "#             DB.session.commit()\n",
    "#         dgo = Record(business_id=row.business_id, cool=row.cool, date=row.data, funny=row.funny,\n",
    "#                      review_id=row.review_id, stars=row.stars, text=row.text, useful=row.useful)\n",
    "#         DB.session.add(dgo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.drop_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for row in np.ascontiguousarray(df.values):\n",
    "     if i % 1000 == 0:\n",
    "        print(i,end=\"\")\n",
    "#       DB.commit() \n",
    "     dgo = review(business_id=row[0], cool=row[1], date=row[2], funny=row[3],\n",
    "                 review_id=row[4], stars=row[5], text=row[6], useful=row[7])\n",
    "     DB.session.add(dgo)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
       "       'useful', 'user_id', 'ctext', 'pstar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 'business_id', 1 'cool', 2 'date', 3 'funny', 4 'review_id', 5 'stars', 6 'text',\n",
    "       7 'useful', 8 'user_id', 9 'ctext', 10 'pstar'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6685900\n",
      "done 100000 done 200000 done 300000 done 400000 done 500000 done 600000 done 700000 done 800000 done 900000 done 1000000 done 1100000 done 1200000 done 1300000 done 1400000 done 1500000 done 1600000 done 1700000 done 1800000 done 1900000 done 2000000 done 2100000 done 2200000 done 2300000 done 2400000 done 2500000 done 2600000 done 2700000 done 2800000 done 2900000 done 3000000 done 3100000 done 3200000 done 3300000 done 3400000 done 3500000 done 3600000 done 3700000 done 3800000 done 3900000 done 4000000 done 4100000 done 4200000 done 4300000 done 4400000 done 4500000 done 4600000 done 4700000 done 4800000 done 4900000 done 5000000 done 5100000 done 5200000 done 5300000 done 5400000 done 5500000 done 5600000 done 5700000 done 5800000 done 5900000 done 6000000 done 6100000 done 6200000 done 6300000 done 6400000 done 6500000 done 6600000 done 6685900 "
     ]
    }
   ],
   "source": [
    "target = df.shape[0]\n",
    "print(target)\n",
    "done = 0\n",
    "step = 100000\n",
    "while done < target:\n",
    "    todo = min(target - done, step)\n",
    "    for row in np.ascontiguousarray(df[done:done+todo].values):\n",
    "        dgo = review(business_id=row[0], date=row[2], stars=row[5], pstars=row[10], text=row[6], ctext=row[9])\n",
    "        DB.session.add(dgo)\n",
    "    DB.session.commit()\n",
    "    done += todo\n",
    "    print('done', done, end=\" \")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.shape[0]\n",
    "done = 0\n",
    "step = 100000\n",
    "while done < target:\n",
    "    todo = min(target - done, step)\n",
    "    for row in np.ascontiguousarray(df[done:done+todo].values):\n",
    "        dgo = Record(business_id=row[0], cool=row[1], date=row[2], funny=row[3],\n",
    "                 review_id=row[4], stars=row[5], text=row[6], useful=row[7])\n",
    "        DB.session.add(dgo)\n",
    "    DB.session.commit()\n",
    "    done += todo\n",
    "    print('done', done, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685900"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class review(DB.Model):\n",
    "    id = DB.Column(DB.Integer, primary_key=True)\n",
    "    business_id = DB.Column(DB.String(25), nullable=False)\n",
    "    cool = DB.Column(DB.BigInteger, nullable=False)\n",
    "    date = DB.Column(DB.DateTime, nullable=False)\n",
    "    funny = DB.Column(DB.BigInteger, nullable=False)\n",
    "    review_id = DB.Column(DB.String(25), nullable=False)\n",
    "    stars = DB.Column(DB.Integer, nullable=False)\n",
    "    text = DB.Column(DB.String(5000), nullable=False)\n",
    "    useful = DB.Column(DB.BigInteger, nullable=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"review_id {self.review_id} ---  star {self.stars}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in DB.session.query(review).filter(review.review_id =='Q1sbwvVQXV2734tPgoKj4Q'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP = Flask(__name__)\n",
    "APP.config['SQLALCHEMY_DATABASE_URI'] = DATABASE_URL\n",
    "APP.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# APP.config['SQLALCHEMY_BINDS'] = {\n",
    "#     'reviewtwo': DATABASE_URL\n",
    "# }\n",
    "APP.config['extend_existing']=True\n",
    "DB = SQLAlchemy(APP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reviewer(DB.Model):\n",
    "    id = DB.Column(DB.Integer, primary_key=True)\n",
    "    user_id = DB.Column(DB.String(22), nullable=False)\n",
    "    name = DB.Column(DB.String(32), nullable=False)\n",
    "    average_stars = DB.Column(DB.Float, nullable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['average_stars', 'compliment_cool', 'compliment_cute',\n",
       "       'compliment_funny', 'compliment_hot', 'compliment_list',\n",
       "       'compliment_more', 'compliment_note', 'compliment_photos',\n",
       "       'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool',\n",
       "       'elite', 'fans', 'friends', 'funny', 'name', 'review_count', 'useful',\n",
       "       'user_id', 'yelping_since'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfu.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index([ 0  'average_stars',1 'compliment_cool', 2'compliment_cute',\n",
    "      3 'compliment_funny', 4'compliment_hot',5 'compliment_list',\n",
    "      6 'compliment_more', 7'compliment_note', 8'compliment_photos',\n",
    "      9 'compliment_plain', 9'compliment_profile', 10'compliment_writer',11 'cool',\n",
    "      12 'elite',13 'fans',14 'friends' 15, 'funny' 16, 'name',17 'review_count',18 'useful',\n",
    "       19'user_id', 'yelping_since'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_stars         float64\n",
       "compliment_cool         int64\n",
       "compliment_cute         int64\n",
       "compliment_funny        int64\n",
       "compliment_hot          int64\n",
       "compliment_list         int64\n",
       "compliment_more         int64\n",
       "compliment_note         int64\n",
       "compliment_photos       int64\n",
       "compliment_plain        int64\n",
       "compliment_profile      int64\n",
       "compliment_writer       int64\n",
       "cool                    int64\n",
       "elite                  object\n",
       "fans                    int64\n",
       "friends                object\n",
       "funny                   int64\n",
       "name                   object\n",
       "review_count            int64\n",
       "useful                  int64\n",
       "user_id                object\n",
       "yelping_since          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfu.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average_stars         float64 0\n",
    "compliment_cool         int64 1\n",
    "compliment_cute         int64 2\n",
    "compliment_funny        int64 3\n",
    "compliment_hot          int64 4\n",
    "compliment_list         int64 5\n",
    "compliment_more         int64 6\n",
    "compliment_note         int64 7\n",
    "compliment_photos       int64 8\n",
    "compliment_plain        int64 9\n",
    "compliment_profile      int64 10\n",
    "compliment_writer       int64 11\n",
    "cool                    int64 12\n",
    "elite                  object 13\n",
    "fans                    int64 14\n",
    "friends                object 15\n",
    "funny                   int64 16\n",
    "name                   object 17\n",
    "review_count            int64 18\n",
    "useful                  int64 19\n",
    "user_id                object 20\n",
    "yelping_since          object 21\n",
    "dtype: object\n",
    "In [39]:\n",
    "￼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637138, 22)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637138\n",
      "done 50000 done 100000 done 150000 done 200000 done 250000 done 300000 done 350000 done 400000 done 450000 done 500000 done 550000 done 600000 done 650000 done 700000 done 750000 done 800000 done 850000 done 900000 done 950000 done 1000000 done 1050000 done 1100000 done 1150000 done 1200000 done 1250000 done 1300000 done 1350000 done 1400000 done 1450000 done 1500000 done 1550000 done 1600000 done 1637138 "
     ]
    }
   ],
   "source": [
    "target = dfu.shape[0]\n",
    "print(target)\n",
    "done = 0\n",
    "step = 50000\n",
    "while done < target:\n",
    "    todo = min(target - done, step)\n",
    "    for row in np.ascontiguousarray(dfu[done:done+todo].values):\n",
    "        dgo = reviewer(user_id=row[20], name=row[17], average_stars=row[0])\n",
    "        DB.session.add(dgo)\n",
    "    DB.session.commit()\n",
    "    done += todo\n",
    "    print('done', done, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load( open( \"region_df_pstar_ptext.pql\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id     object\n",
       "cool             int64\n",
       "date            object\n",
       "funny            int64\n",
       "review_id       object\n",
       "stars          float64\n",
       "text            object\n",
       "useful           int64\n",
       "user_id         object\n",
       "ctext           object\n",
       "pstar          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "business_id     object 0\n",
    "cool             int64 1\n",
    "date            object 2\n",
    "funny            int64 3\n",
    "review_id       object 4\n",
    "stars          float64 5\n",
    "text            object 6\n",
    "useful           int64 7\n",
    "user_id         object 8\n",
    "ctext           object 9\n",
    "pstar          float64 10\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP = Flask(__name__)\n",
    "APP.config['SQLALCHEMY_DATABASE_URI'] = DATABASE_URL\n",
    "APP.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# APP.config['SQLALCHEMY_BINDS'] = {\n",
    "#     'reviewtwo': DATABASE_URL\n",
    "# }\n",
    "APP.config['extend_existing']=True\n",
    "DB = SQLAlchemy(APP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class review(DB.Model):\n",
    "    id = DB.Column(DB.Integer, primary_key=True)\n",
    "    business_id = DB.Column(DB.String(25), nullable=False)\n",
    "    date = DB.Column(DB.DateTime, nullable=False)\n",
    "    stars = DB.Column(DB.Integer, nullable=False)\n",
    "    pstars = DB.Column(DB.Integer, nullable=False)\n",
    "    text = DB.Column(DB.String(5000), nullable=False)\n",
    "    ctext = DB.Column(DB.String(5000), nullable=False)\n",
    "    user_id = DB.Column(DB.String(25), nullable=False)\n",
    "    review_id = DB.Column(DB.String(25), nullable=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Data {self.date} ---  Text {self.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['business_id', 'user_id', 'review_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ctext</th>\n",
       "      <th>pstar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4839972</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-16 00:27:50</td>\n",
       "      <td>0</td>\n",
       "      <td>8UsalYi1Jkbk8WitFEa_aQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Spicy Amigos is the old Jalapeños. I'm not sur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1b4rlFFdNfeysOjbrFykng</td>\n",
       "      <td>spicy amigos old jalapeños sure owners changed...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108967</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-26 17:27:49</td>\n",
       "      <td>0</td>\n",
       "      <td>X4PwY0mMHxqOf2O1pwYdIQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Delicious! One of the best burritos, salsa and...</td>\n",
       "      <td>0</td>\n",
       "      <td>4YHZzwlxEMi7zWO6Osszdw</td>\n",
       "      <td>delicious one best burritos salsa vegetables c...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783181</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-13 19:01:34</td>\n",
       "      <td>0</td>\n",
       "      <td>C_pdS4RGgrPrt4ctYOrQ0A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>One of the better down to earth Tacos I have h...</td>\n",
       "      <td>0</td>\n",
       "      <td>A4bpHuvzaQt9-XAg8e9Msw</td>\n",
       "      <td>one better earth tacos calgary authentic clean...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867118</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-11-14 20:09:54</td>\n",
       "      <td>0</td>\n",
       "      <td>aIzkfP0-30mpNcBo9MsjmA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great Mexican joint in the west side of downto...</td>\n",
       "      <td>1</td>\n",
       "      <td>BgTWMo2qRrXINPiM35w8zw</td>\n",
       "      <td>great mexican joint west side downtown much be...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220326</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-06 04:22:48</td>\n",
       "      <td>0</td>\n",
       "      <td>8QUwzeXeyJ3L15lKfhKLsQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I had the chicken Tinga enchilada in mole sauc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bsy9F-59sl9OT_bvZNl3hA</td>\n",
       "      <td>chicken tinga enchilada mole sauce chicken dry...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    business_id  ...    pstar\n",
       "4839972  --1UhMGODdWsrMastO9DZw  ...      4.0\n",
       "5108967  --1UhMGODdWsrMastO9DZw  ...      4.0\n",
       "4783181  --1UhMGODdWsrMastO9DZw  ...      4.0\n",
       "4867118  --1UhMGODdWsrMastO9DZw  ...      4.0\n",
       "5220326  --1UhMGODdWsrMastO9DZw  ...      3.0\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "business_id     object 0\n",
    "cool             int64 1\n",
    "date            object 2\n",
    "funny            int64 3\n",
    "review_id       object 4\n",
    "stars          float64 5\n",
    "text            object 6\n",
    "useful           int64 7\n",
    "user_id         object 8\n",
    "ctext           object 9\n",
    "pstar          float64 10\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6685900\n",
      "done 100000 done 200000 done 300000 done 400000 done 500000 done 600000 done 700000 done 800000 done 900000 done 1000000 done 1100000 done 1200000 done 1300000 done 1400000 done 1500000 done 1600000 done 1700000 done 1800000 done 1900000 done 2000000 done 2100000 done 2200000 done 2300000 done 2400000 done 2500000 done 2600000 done 2700000 done 2800000 done 2900000 done 3000000 done 3100000 done 3200000 done 3300000 done 3400000 done 3500000 done 3600000 done 3700000 done 3800000 done 3900000 done 4000000 done 4100000 done 4200000 done 4300000 done 4400000 done 4500000 done 4600000 done 4700000 done 4800000 done 4900000 done 5000000 done 5100000 done 5200000 done 5300000 done 5400000 done 5500000 done 5600000 done 5700000 done 5800000 done 5900000 done 6000000 done 6100000 done 6200000 done 6300000 done 6400000 done 6500000 done 6600000 done 6685900 "
     ]
    }
   ],
   "source": [
    "target = df_sorted.shape[0]\n",
    "print(target)\n",
    "done = 0\n",
    "step = 100000\n",
    "while done < target:\n",
    "    todo = min(target - done, step)\n",
    "    for row in np.ascontiguousarray(df_sorted[done:done+todo].values):\n",
    "        dgo = review(business_id=row[0], date=row[2], stars=row[5], pstars=row[10], text=row[6], ctext=row[9],\n",
    "                    user_id = row[8], review_id = row[4])\n",
    "        DB.session.add(dgo)\n",
    "    DB.session.commit()\n",
    "    done += todo\n",
    "    print('done', done, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
